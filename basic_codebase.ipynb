{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import paramiko\n",
    " \n",
    "# Python Image Library\n",
    "from PIL import Image #works only in local env\n",
    "\n",
    "from naoqi import ALProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAOIP = '192.168.0.241'\n",
    "PORT = 9559\n",
    "NAME = \"nao\"\n",
    "passwd = \"19981\"\n",
    "\n",
    "## TEST\n",
    "tts = 'ALTextToSpeech'\n",
    "text = ALProxy(tts, NAOIP, PORT)\n",
    "text.say(\"Hi NAOsolutions, thanks that you guys develop me further!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected....\n",
      "Connection ended...\n"
     ]
    }
   ],
   "source": [
    "paramiko.util.log_to_file(\"paramiko.log\")\n",
    "\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "ssh.connect(NAOIP, username=NAME, password=passwd)\n",
    "#######\n",
    "print(\"Connected....\")\n",
    "#######\n",
    "ssh.close()\n",
    "print(\"Connection ended...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition delay  1.45231795311\n"
     ]
    }
   ],
   "source": [
    "def showNaoImage(IP, PORT,camera,resolution, colorSpace):\n",
    "  \"\"\"\n",
    "  First get an image from Nao, then show it on the screen with PIL.\n",
    "  \"\"\"\n",
    "  camProxy = ALProxy(\"ALVideoDevice\", IP, PORT)\n",
    "  videoClient = camProxy.subscribeCamera(\"python_client\",0, resolution, colorSpace, 5)\n",
    "  t0 = time.time()\n",
    "\n",
    "  # Get a camera image.\n",
    "  # image[6] contains the image data passed as an array of ASCII chars.\n",
    "  naoImage = camProxy.getImageRemote(videoClient)\n",
    "  t1 = time.time()\n",
    "  \n",
    "  # Time the image transfer.\n",
    "  print \"acquisition delay \", t1 - t0\n",
    "  camProxy.unsubscribe(videoClient)\n",
    "\n",
    "  # Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "  # package.\n",
    "\n",
    " \n",
    "  # Get the image size and pixel array.\n",
    "  imageWidth = naoImage[0]\n",
    "  imageHeight = naoImage[1]\n",
    "  array = naoImage[6]\n",
    "\n",
    "\n",
    "  # Create a PIL Image from our pixel array.\n",
    "  im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), array)\n",
    "\n",
    "  # Save the image.\n",
    "  im.save(\"camImage.png\", \"PNG\")\n",
    "  im.show()\n",
    "\n",
    "\n",
    "camera = 1 # 0 = top camera, 1 = bottom camera\n",
    "\n",
    "resolution = 3 # 0 = QQVGA, 1 = QVGA, 2 = VGA\n",
    "\n",
    "colorSpace = 11 # http://doc.aldebaran.com/2-5/family/robots/video_robot.html#cameracolorspace-mt9m114\n",
    "\n",
    "naoImage = showNaoImage(NAOIP, PORT,camera,resolution, colorSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "photoCaptureProxy = ALProxy(\"ALPhotoCapture\", NAOIP, PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes 3 pictures\n",
    "photoCaptureProxy.setResolution(2)\n",
    "photoCaptureProxy.setPictureFormat(\"jpg\")\n",
    "photoCaptureProxy = photoCaptureProxy.takePictures(3, \"/home/nao/recordings/cameras/\", \"image\") #3 picturess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech recognization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechProxy = ALProxy(\"ALSpeechRecognition\", NAOIP, PORT)\n",
    "speechProxy.setLanguage(\"English\")\n",
    "#######\n",
    "vocabulary = [\"yes\", \"no\", \"please\"]\n",
    "speechProxy.setVocabulary(vocabulary, False)\n",
    "#######\n",
    "speechProxy.subscribe(\"Test_ASR\")\n",
    "print 'Speech recognition engine started'\n",
    "time.sleep(20)\n",
    "speechProxy.unsubscribe(\"Test_ASR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/google/auth/crypt/_cryptography_rsa.py:22: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  import cryptography.exceptions\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1 as speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(config, audio):\n",
    "    client = speech.SpeechClient.from_service_account_file(\"key_for_google.json\")\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    print_sentences(response)\n",
    "\n",
    "\n",
    "def print_sentences(response):\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        confidence = best_alternative.confidence\n",
    "        print \"-\" * 80\n",
    "        print \"Transcript:\", transcript\n",
    "        print \"Confidence:\", confidence*100,\"%\"\n",
    "\n",
    "\n",
    "config = dict(language_code=\"en-US\")\n",
    "audio = dict(uri=\"gs://cloud-samples-data/speech/brooklyn_bridge.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Transcript: how old is the Brooklyn Bridge\n",
      "Confidence: 98.2160568237 %\n"
     ]
    }
   ],
   "source": [
    "speech_to_text(config, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio transcripts into text ...\n",
      "what if somebody decides to break it be careful that you keep adequate coverage but look for places to save money baby it's taking longer to get things squared away than the bankers expected during the wife for once company may win her tax hated retirement income as helpful as our cost on the two naked bone when the title of this type of song is in question there's no dying or waxing or gassing needed maybe personalized leather hard at work on a flat surface and smooth out the simplest kind of separate system uses a single self-contained unit the old shop at it still holds a good mechanic is usually a bad boss both figures would go higher in later years cabinets chest doll houses at set\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile('test_audio.wav') as source:\n",
    "    audio_text = r.listen(source)\n",
    "    try:\n",
    "        # using google speech recognition\n",
    "        text = r.recognize_google(audio_text)\n",
    "        print('Converting audio transcripts into text ...')\n",
    "        print(text)\n",
    "    except:\n",
    "            print('Sorry.. run again...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with mic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9cdf45c8f73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Talk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maudio_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time over, thanks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# set up PyAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pyaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36mget_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find PyAudio; check installation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.2.11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    print(\"Talk\")\n",
    "    audio_text = r.listen(source)\n",
    "    print(\"Time over, thanks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognize(time):\n",
    "    with sr.Microphone() as source:\n",
    "        self.r.adjust_for_ambient_noise(source)\n",
    "        print 'mic on... start recording!'\n",
    "        audio = self.r.listen(source, phrase_time_limit=time)\n",
    "        try:\n",
    "            print 'Reconized words: ' + self.r.recognize_google(audio)\n",
    "            return self.r.recognize_google(audio)\n",
    "        except LookupError, e:\n",
    "            print e\n",
    "            return 'there was an error!'\n",
    "        except sr.UnknownValueError, e:\n",
    "            print e\n",
    "            print 'what do you mean? i do not understand'\n",
    "            return ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
