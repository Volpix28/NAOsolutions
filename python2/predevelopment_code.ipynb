{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
      "\u001b[0;32m<ipython-input-1-1371aec4ea78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mparamiko\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import paramiko\n",
    "import scipy\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "import calendar\n",
    "import speech_recognition as sr\n",
    "from dialog import Dialog\n",
    " \n",
    "# Python Image Library\n",
    "from PIL import Image #works only in local env\n",
    "\n",
    "from naoqi import ALProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAOIP = '192.168.0.242'\n",
    "PORT = 9559\n",
    "NAME = \"nao\"\n",
    "passwd = \"19981\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps = 'ALRobotPosture'\n",
    "ropo = ALProxy(rps, NAOIP, PORT)\n",
    "#ropo.goToPosture(\"Stand\", 1.0)\n",
    "ropo.goToPosture(\"Crouch\", 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = paramiko.Transport((NAOIP, 22))\n",
    "transport.connect(username=NAME, password=passwd)\n",
    "print \"Connected to transport.......\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio file and paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to transport.......\n"
     ]
    }
   ],
   "source": [
    "transport = paramiko.Transport((NAOIP, 22))\n",
    "transport.connect(username=NAME, password=passwd)\n",
    "print \"Connected to transport.......\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(NAOIP, PORT, t):\n",
    "    recorderProxy = ALProxy(\"ALAudioRecorder\", NAOIP, PORT)\n",
    "    leds = ALProxy(\"ALLeds\",NAOIP,PORT)\n",
    "    recorderProxy.stopMicrophonesRecording()\n",
    "    nao_recordings_path = \"/home/nao/nao_solutions/wavs/\"\n",
    "    \n",
    "    #settings\n",
    "    time_stamp = str(calendar.timegm(time.gmtime()))\n",
    "    audioName = r'name_' + time_stamp + r'.wav'\n",
    "    remoteaudiofilepath = nao_recordings_path+audioName\n",
    "\n",
    "    # configure channels\n",
    "    # left, right, front rear (mics?)\n",
    "    channels = (0, 0, 1, 0); # python tuple, C++ code uses AL:ALValue\n",
    "    audio_file = recorderProxy.startMicrophonesRecording(\"/home/nao/nao_solutions/wavs/\"+audioName, \"wav\", 16000, channels)\n",
    "    #audio_file = recorderProxy.post.startMicrophonesRecording(\"/home/nao/nao_solutions/wavs/\"+audioName, \"wav\", 16000, channels)\n",
    "    #leds.rotateEyes(0x000000FF,1,t)\n",
    "    # continue recording for t seconds\n",
    "    time.sleep(t)\n",
    "\n",
    "    # stop recording\n",
    "    recorderProxy.stopMicrophonesRecording()\n",
    "    \n",
    "    return remoteaudiofilepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognition(remoteaudiofilepath):\n",
    "    sftp = transport.open_sftp_client()\n",
    "    audio_file = sftp.open(remoteaudiofilepath)\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as file:\n",
    "        audio_file = r.listen(file)\n",
    "        try:\n",
    "            # using google speech recognition\n",
    "            text_data = str(r.recognize_google(audio_file))\n",
    "            #print('Converting audio transcripts into text ...')\n",
    "            #print(text_data)\n",
    "            sftp.remove(remoteaudiofilepath)\n",
    "            return text_data\n",
    "        except sr.UnknownValueError:\n",
    "            sftp.remove(remoteaudiofilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-517e5a4cacc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mconformation\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorry_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconformation_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_of_user\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconformation_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconformation_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mrecording\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# while test\n",
    "text.say(Dialog.say_name)\n",
    "recording = record_audio(NAOIP, PORT, 5)\n",
    "name_of_user = speech_recognition(recording)\n",
    "\n",
    "while name_of_user == None:\n",
    "    text.say(Dialog.sorry_message[0])\n",
    "    time.sleep(1)\n",
    "    text.say(Dialog.say_name)\n",
    "    recording = record_audio(NAOIP, PORT, 5)\n",
    "    name_of_user = speech_recognition(recording)\n",
    "    continue\n",
    "\n",
    "text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1])\n",
    "recording = record_audio(NAOIP, PORT, 3)\n",
    "conformation = speech_recognition(recording)\n",
    "\n",
    "while conformation not in [\"yes\", \"no\"]:\n",
    "    text.say(Dialog.sorry_message[1])\n",
    "    time.sleep(1)\n",
    "    text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1] + Dialog.conformation_message[2])\n",
    "    recording = record_audio(NAOIP, PORT, 3)\n",
    "    conformation = speech_recognition(recording)\n",
    "    print(conformation)\n",
    "    continue\n",
    "\n",
    "while conformation in [\"yes\", \"no\"]:\n",
    "    if conformation == 'yes':\n",
    "        text.say(Dialog.conformation_message[3] + name_of_user + Dialog.conformation_message[4])\n",
    "        break\n",
    "\n",
    "    elif conformation == 'no':\n",
    "        text.say(Dialog.sorry_message[2])\n",
    "        recording = record_audio(NAOIP, PORT, 5)\n",
    "        name_of_user = speech_recognition(recording)\n",
    "\n",
    "        while name_of_user == None:\n",
    "            text.say(Dialog.sorry_message[0])\n",
    "            time.sleep(1)\n",
    "            text.say(Dialog.say_name)\n",
    "            recording = record_audio(NAOIP, PORT, 5)\n",
    "            name_of_user = speech_recognition(recording)\n",
    "            continue\n",
    "\n",
    "        text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1])\n",
    "        recording = record_audio(NAOIP, PORT, 3)\n",
    "        conformation = speech_recognition(recording)\n",
    "\n",
    "        while conformation not in [\"yes\", \"no\"]:\n",
    "            text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1] + Dialog.conformation_message[2])\n",
    "            time.sleep(1)\n",
    "            text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1])\n",
    "            recording = record_audio(NAOIP, PORT, 3)\n",
    "            conformation = speech_recognition(recording)\n",
    "            continue\n",
    "\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_name(NAOIP, PORT, record_name_time):\n",
    "    text.say(Dialog.say_name)\n",
    "    recording = record_audio(NAOIP, PORT, record_name_time)\n",
    "    name_of_user = speech_recognition(recording)\n",
    "    return name_of_user\n",
    "\n",
    "def name_loop(NAOIP, PORT, record_name_time, name_of_user):\n",
    "    while name_of_user == None:\n",
    "        text.say(Dialog.sorry_message[0])\n",
    "        time.sleep(1)\n",
    "        name_of_user = record_name(NAOIP, PORT, record_name_time)\n",
    "        continue\n",
    "    return name_of_user\n",
    "\n",
    "\n",
    "def confirm(NAOIP, PORT, record_confirm_time, name_of_user):\n",
    "    text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1])\n",
    "    recording = record_audio(NAOIP, PORT, record_confirm_time)\n",
    "    conformation = speech_recognition(recording)\n",
    "    return conformation\n",
    "\n",
    "\n",
    "def confirm_loop(NAOIP, PORT, record_confirm_time, sorry_message, conformation, name_of_user):\n",
    "    while conformation not in [\"yes\", \"no\"]:\n",
    "        text.say(Dialog.sorry_message[sorry_message])\n",
    "        time.sleep(1)\n",
    "        text.say(Dialog.conformation_message[0] + name_of_user + Dialog.conformation_message[1] + Dialog.conformation_message[2])\n",
    "        recording = record_audio(NAOIP, PORT, record_confirm_time)\n",
    "        conformation = speech_recognition(recording)\n",
    "        continue\n",
    "    return conformation\n",
    "\n",
    "\n",
    "def knowledgebase_entry(NAOIP, PORT, record_confirm_time, sorry_message, conformation, name_of_user):\n",
    "    while conformation in [\"yes\", \"no\"]:\n",
    "        if conformation == 'yes':\n",
    "            text.say(Dialog.conformation_message[3] + name_of_user + Dialog.conformation_message[4])\n",
    "            # API REQUEST add name \n",
    "            break\n",
    "\n",
    "        elif conformation == 'no':\n",
    "            text.say(Dialog.sorry_message[2])\n",
    "            recording = record_audio(NAOIP, PORT, 5)\n",
    "            name_of_user = speech_recognition(recording)\n",
    "\n",
    "            name_of_user = name_loop(NAOIP, PORT, record_confirm_time, name_of_user)\n",
    "\n",
    "            conformation = confirm(NAOIP, PORT, record_confirm_time, name_of_user)\n",
    "\n",
    "            conformation = confirm_loop(NAOIP, PORT, record_confirm_time, sorry_message, conformation, name_of_user)\n",
    "\n",
    "            continue\n",
    "    return name_of_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'open_sftp_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0a53b89fd11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_and_save_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-0a53b89fd11c>\u001b[0m in \u001b[0;36mget_and_save_name\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_and_save_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mname_of_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mname_of_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_of_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfirm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_of_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfirm_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_of_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-c9b2900ad097>\u001b[0m in \u001b[0;36mrecord_name\u001b[0;34m(NAOIP, PORT, record_name_time)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msay_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrecording\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_name_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mname_of_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech_recognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecording\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mname_of_user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-0d03abfe1d64>\u001b[0m in \u001b[0;36mspeech_recognition\u001b[0;34m(remoteaudiofilepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspeech_recognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremoteaudiofilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msftp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_sftp_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremoteaudiofilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'open_sftp_client'"
     ]
    }
   ],
   "source": [
    "def get_and_save_name():\n",
    "    name_of_user = record_name(NAOIP, PORT, 5)\n",
    "    name_of_user = name_loop(NAOIP, PORT, 5, name_of_user)\n",
    "    conformation = confirm(NAOIP, PORT, 3, name_of_user)\n",
    "    conformation = confirm_loop(NAOIP, PORT, 3, 0, conformation, name_of_user)\n",
    "    final_name = knowledgebase_entry(NAOIP, PORT, 3, 0, conformation, name_of_user)\n",
    "    return final_name\n",
    "    \n",
    "test_name = get_and_save_name()\n",
    "print(test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InBuilt with vocubalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocabulary = ['Marcel', 'Lukas', 'Alexander', 'Matthias']\n",
    "asr = ALProxy(\"ALSpeechRecognition\", NAOIP, PORT)\n",
    "asr.setLanguage(\"English\")\n",
    "asr.setVocabulary(vocabulary, False)\n",
    "asr.subscribe(\"Test_ASR\")\n",
    "print 'Speech recognition engine started'\n",
    "time.sleep(5)\n",
    "asr.unsubscribe(\"Test_ASR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition delay  1.92421603203\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c840ede83df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mcolorSpace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m \u001b[0;31m# http://doc.aldebaran.com/2-5/family/robots/video_robot.html#cameracolorspace-mt9m114\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mnaoImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshowNaoImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAOIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorSpace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-c840ede83df0>\u001b[0m in \u001b[0;36mshowNaoImage\u001b[0;34m(IP, PORT, camera, resolution, colorSpace)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# Save the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mimNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m900000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mimName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimNumber\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PNG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "def showNaoImage(IP, PORT,camera,resolution, colorSpace):\n",
    "  \"\"\"\n",
    "  First get an image from Nao, then show it on the screen with PIL.\n",
    "  \"\"\"\n",
    "  camProxy = ALProxy(\"ALVideoDevice\", IP, PORT)\n",
    "  videoClient = camProxy.subscribeCamera(\"python_client\",0, resolution, colorSpace, 5)\n",
    "  t0 = time.time()\n",
    "\n",
    "  # Get a camera image.\n",
    "  # image[6] contains the image data passed as an array of ASCII chars.\n",
    "  naoImage = camProxy.getImageRemote(videoClient)\n",
    "  t1 = time.time()\n",
    "  \n",
    "  # Time the image transfer.\n",
    "  print \"acquisition delay \", t1 - t0\n",
    "  camProxy.unsubscribe(videoClient)\n",
    "\n",
    "  # Now we work with the image returned and save it as a PNG  using ImageDraw\n",
    "  # package.\n",
    "\n",
    " \n",
    "  # Get the image size and pixel array.\n",
    "  imageWidth = naoImage[0]\n",
    "  imageHeight = naoImage[1]\n",
    "  array = naoImage[6]\n",
    "\n",
    "\n",
    "  # Create a PIL Image from our pixel array.\n",
    "  im = Image.frombytes(\"RGB\", (imageWidth, imageHeight), array)\n",
    "\n",
    "  # Save the image.\n",
    "  imNumber = random.randint(0,900000000)\n",
    "  imName = \"image_\" + imNumber + \".png\"\n",
    "  im.save(imName, \"PNG\") \n",
    "  im.show()\n",
    "\n",
    "\n",
    "camera = 1 # 0 = top camera, 1 = bottom camera\n",
    "\n",
    "resolution = 3 # 0 = QQVGA, 1 = QVGA, 2 = VGA\n",
    "\n",
    "colorSpace = 11 # http://doc.aldebaran.com/2-5/family/robots/video_robot.html#cameracolorspace-mt9m114\n",
    "\n",
    "naoImage = showNaoImage(NAOIP, PORT,camera,resolution, colorSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "photoCaptureProxy = ALProxy(\"ALPhotoCapture\", NAOIP, PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes 3 pictures\n",
    "photoCaptureProxy.setResolution(2)\n",
    "photoCaptureProxy.setPictureFormat(\"jpg\")\n",
    "photoCaptureProxy = photoCaptureProxy.takePictures(3, \"/home/nao/recordings/cameras/\", \"image\") #3 picturess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech recognization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechProxy = ALProxy(\"ALSpeechRecognition\", NAOIP, PORT)\n",
    "speechProxy.setLanguage(\"English\")\n",
    "#######\n",
    "vocabulary = [\"yes\", \"no\", \"please\"]\n",
    "speechProxy.setVocabulary(vocabulary, False)\n",
    "#######\n",
    "speechProxy.subscribe(\"Test_ASR\")\n",
    "print 'Speech recognition engine started'\n",
    "time.sleep(20)\n",
    "speechProxy.unsubscribe(\"Test_ASR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(config, audio):\n",
    "    client = speech.SpeechClient.from_service_account_file(\"key_for_google.json\")\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    print_sentences(response)\n",
    "\n",
    "\n",
    "def print_sentences(response):\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        confidence = best_alternative.confidence\n",
    "        print \"-\" * 80\n",
    "        print \"Transcript:\", transcript\n",
    "        print \"Confidence:\", confidence*100,\"%\"\n",
    "\n",
    "\n",
    "config = dict(language_code=\"en-US\")\n",
    "audio = dict(uri=\"gs://cloud-samples-data/speech/brooklyn_bridge.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6987570374806658\n"
     ]
    }
   ],
   "source": [
    "print(random.randint(1,20000000000000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Transcript: how old is the Brooklyn Bridge\n",
      "Confidence: 98.2160568237 %\n"
     ]
    }
   ],
   "source": [
    "speech_to_text(config, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with mic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio transcripts into text ...\n",
      "what if somebody decides to break it be careful that you keep adequate coverage but look for places to save money baby it's taking longer to get things squared away than the bankers expected during the wife for once company may win her tax hated retirement income as helpful as our cost on the two naked bone when the title of this type of song is in question there's no dying or waxing or gassing needed maybe personalized leather hard at work on a flat surface and smooth out the simplest kind of separate system uses a single self-contained unit the old shop at it still holds a good mechanic is usually a bad boss both figures would go higher in later years cabinets chest doll houses at set\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.AudioFile('test_audio.wav') as source:\n",
    "    audio_text = r.listen(source)\n",
    "# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "    try:\n",
    "        # using google speech recognition\n",
    "        text = r.recognize_google(audio_text)\n",
    "        print('Converting audio transcripts into text ...')\n",
    "        print(text)\n",
    "    except:\n",
    "         print('Sorry.. run again...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9cdf45c8f73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Talk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maudio_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time over, thanks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# set up PyAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pyaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36mget_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find PyAudio; check installation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.2.11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    print(\"Talk\")\n",
    "    audio_text = r.listen(source)\n",
    "    print(\"Time over, thanks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognize(time):\n",
    "    with sr.Microphone() as source:\n",
    "        self.r.adjust_for_ambient_noise(source)\n",
    "        print 'mic on... start recording!'\n",
    "        audio = self.r.listen(source, phrase_time_limit=time)\n",
    "        try:\n",
    "            print 'Reconized words: ' + self.r.recognize_google(audio)\n",
    "            return self.r.recognize_google(audio)\n",
    "        except LookupError, e:\n",
    "            print e\n",
    "            return 'there was an error!'\n",
    "        except sr.UnknownValueError, e:\n",
    "            print e\n",
    "            print 'what do you mean? i do not understand'\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-86209f7df2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeech_recognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-86dc1efd30a3>\u001b[0m in \u001b[0;36mspeech_recognize\u001b[0;34m(time)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspeech_recognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'mic on... start recording!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase_time_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# set up PyAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pyaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/speech_recognition/__init__.pyc\u001b[0m in \u001b[0;36mget_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find PyAudio; check installation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.2.11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "speech_recognize(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "AzureBlobFileUploader instance has no attribute 'blob_service_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7f9990a680b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Initialize class and upload files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mazure_blob_file_uploader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAzureBlobFileUploader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mazure_blob_file_uploader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"camImage.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m#azure_blob_file_uploader.upload_all_images_in_folder()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7f9990a680b4>\u001b[0m in \u001b[0;36mupload_image\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Create blob with same name as local file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     blob_client = self.blob_service_client.get_blob_client(container=MY_IMAGE_CONTAINER,\n\u001b[0m\u001b[1;32m     38\u001b[0m                                                           blob=file_name)\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Get full path to the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: AzureBlobFileUploader instance has no attribute 'blob_service_client'"
     ]
    }
   ],
   "source": [
    "# upload_blob_images.py\n",
    "# Python program to bulk upload jpg image files as blobs to azure storage\n",
    "# Uses latest python SDK() for Azure blob storage\n",
    "# Requires python 3.6 or above\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from azure.storage.blob import ContentSettings, ContainerClient\n",
    " \n",
    "# IMPORTANT: Replace connection string with your storage account connection string\n",
    "# Usually starts with DefaultEndpointsProtocol=https;...\n",
    "MY_CONNECTION_STRING = \"DefaultEndpointsProtocol=https;AccountName=naosolutions;AccountKey=KSm+ILWzl3flTorUz0/u6AMu78BLFBV/pIP5apzETmJdqw84pWJXVRS/EqCDdoEChchfASt69xsU+AStVmimaQ==;EndpointSuffix=core.windows.net\"\n",
    " \n",
    "# Replace with blob container. This should be already created in azure storage.\n",
    "MY_IMAGE_CONTAINER = \"naosolutionscontainer\"\n",
    " \n",
    "# Replace with the local folder which contains the image files for upload\n",
    "LOCAL_IMAGE_PATH = r\"/workspaces/NAOsolutions/nao_container/Notebooks/NAO_code/camImage.png\"\n",
    " \n",
    "class AzureBlobFileUploader:\n",
    "  def init(self):\n",
    "    print(\"Intializing AzureBlobFileUploader\")\n",
    " \n",
    "    # Initialize the connection to Azure storage account\n",
    "    self.blob_service_client =  BlobServiceClient.from_connection_string(MY_CONNECTION_STRING)\n",
    " \n",
    "  def upload_all_images_in_folder(self):\n",
    "    # Get all files with jpg extension and exclude directories\n",
    "    all_file_names = [f for f in os.listdir(LOCAL_IMAGE_PATH)\n",
    "                    if os.path.isfile(os.path.join(LOCAL_IMAGE_PATH, f)) and \".jpg\" in f]\n",
    " \n",
    "    # Upload each file\n",
    "    for file_name in all_file_names:\n",
    "      self.upload_image(file_name)\n",
    " \n",
    "  def upload_image(self,file_name):\n",
    "    # Create blob with same name as local file name\n",
    "    blob_client = self.blob_service_client.get_blob_client(container=MY_IMAGE_CONTAINER,\n",
    "                                                          blob=file_name)\n",
    "    # Get full path to the file\n",
    "    upload_file_path = os.path.join(LOCAL_IMAGE_PATH, file_name)\n",
    " \n",
    "    # Create blob on storage\n",
    "    # Overwrite if it already exists!\n",
    "    image_content_setting = ContentSettings(content_type='image/jpeg')\n",
    "    #print(f\"uploading file - {file_name}\")\n",
    "    with open(upload_file_path, \"rb\") as data:\n",
    "      blob_client.upload_blob(data,overwrite=True,content_settings=image_content_setting)\n",
    " \n",
    " \n",
    "# Initialize class and upload files\n",
    "azure_blob_file_uploader = AzureBlobFileUploader()\n",
    "azure_blob_file_uploader.upload_image(\"camImage.png\")\n",
    "#azure_blob_file_uploader.upload_all_images_in_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Matthias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takePictureNew(IP, PORT, camera, resolution, colorSpace, location):\n",
    "  camProxy = ALProxy('ALVideoDevice', IP, PORT)\n",
    "  videoClient = camProxy.subscribeCamera('python_client', camera, resolution, colorSpace, 5)\n",
    "  naoImage = camProxy.getImageRemote(videoClient)\n",
    "  camProxy.unsubscribe(videoClient)\n",
    "  imageName = 'image_' + str(calendar.timegm(time.gmtime())) + '.png' # example: image_{time_stamp}.png\n",
    "  im = Image.frombytes('RGB', (naoImage[0], naoImage[1]), naoImage[6]) # naoImage[0] = width, naoImage[1] = height, naoImage[6] = image data in ASCII char array\n",
    "  im.save(location + os.sep + imageName, 'PNG')\n",
    "  print('Image: ' + imageName + ' successfully saved @ ' + location)\n",
    "  return imageName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: image_1668943584.png successfully saved @ .\n"
     ]
    }
   ],
   "source": [
    "camera = 1 # 0 = top camera, 1 = bottom camera\n",
    "resolution = 3 # 0 = QQVGA, 1 = QVGA, 2 = VGA\n",
    "colorSpace = 11 # http://doc.aldebaran.com/2-5/family/robots/video_robot.html#cameracolorspace-mt9m114\n",
    "# naoImage = takePicture(NAOIP, PORT, camera, resolution, colorSpace)\n",
    "naoImage = takePictureNew(NAOIP, PORT, camera, resolution, colorSpace, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
